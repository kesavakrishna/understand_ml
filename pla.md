Perceptron Learning Algorithm

## **1. Purpose & Intuition**
The perceptron is one of the earliest and simplest algorithms for supervised classification.

It finds a linear decision boundary that separates two classes.

Goal: Find weight w and bias b such that:

sign(wÂ·x + b) = y

for all training points (x,y) where y âˆˆ {+1, âˆ’1}.

Core idea: Start with some guess for w and b, then iteratively nudge them when we misclassify a point.

## **2. Geometry of the Decision Boundary**

The decision rule:

sign(wÂ·x + b)

w is perpendicular (normal) to the decision boundary. The bias b shifts the line (in 2D) or hyperplane (in higher dimensions).

## Why is w perpendicular to the decision boundary?

In 2D, the decision boundary equation is:

wâ‚€xâ‚€ + wâ‚xâ‚ + b = 0

Think of this as:

wÂ·x + b = 0

A dot product wÂ·x is constant for all points on the boundary.

The set of all points with wÂ·x = c is a line (or plane in higher dimensions) perpendicular to w.

That's because the dot product measures projection along w â€” so if you change your position along w, you change wÂ·x; but if you move sideways (perpendicular to w), the dot product stays the same.

**Example in 2D:**

If w=(2,1), the boundary equation is:

2x + 1y + b = 0

The vector (2,1) points straight out from the line.

Walking parallel to the line keeps 2x + y the same.

Walking along (2,1) moves you "away" from the boundary.

ğŸ“Œ **Bias b**

If b = 0, the line passes through the origin.

Changing b shifts the line parallel to itself.

So b controls where the perpendicular line sits.

Example in 2D:

Equation wâ‚€xâ‚€ + wâ‚xâ‚ + b = 0 defines a line.

Points where wÂ·x + b > 0 â†’ classified as +1.

Points where wÂ·x + b < 0 â†’ classified as âˆ’1.

## 3. **The Update Rule**

Given a training point (xáµ¢, yáµ¢):

If correctly classified: do nothing.

If misclassified: update as:

w â† w + yáµ¢xáµ¢
b â† b + yáµ¢


### Why does this work?

If yáµ¢ = +1 and the point is misclassified, it means wÂ·xáµ¢ + b < 0. Adding yáµ¢xáµ¢ moves w towards xáµ¢, making wÂ·xáµ¢ larger.

If yáµ¢ = âˆ’1 and it's misclassified, wÂ·xáµ¢ + b > 0. Adding yáµ¢xáµ¢ moves w away from xáµ¢, decreasing wÂ·xáµ¢.

## 4. **Convergence Guarantee**

If the data is linearly separable, PLA will converge in a finite number of steps.

Proof idea:

Show that the projection of w onto w* (the perfect separator) increases with every update.

Show that the length of w grows at most linearly with steps.

Use these two facts to bound the number of updates.

Bound:

**updates â‰¤ (R / Î³)Â²** steps

where:

- R = max norm of any xáµ¢
- Î³ = margin of separation

## **. Why does PLA converge?**

This is the **Convergence Theorem** for the Perceptron:

If the data is:

- Linearly separable
- Has maximum point length R
- Has a separation margin Î³ (distance from the closest point to the separating boundary)

Then **PLA will stop in at most**:

**updates â‰¤ (R / Î³)Â²** steps.

---

### **Key intuition behind the proof**

Let:

w* = "perfect" weight vector that classifies all points correctly and has ||w*|| = 1.

Î³ = the margin, meaning: yáµ¢(w* Â· xáµ¢) â‰¥ Î³ for all i

R = maxáµ¢ ||xáµ¢|| (largest point length).

---

### Step 1: Every update **aligns w more with wâˆ—**

When you make a mistake on (xáµ¢, yáµ¢), you do:

w â† w + yáµ¢xáµ¢

Since yáµ¢(w* Â· xáµ¢) â‰¥ Î³, this update increases the projection:

w_new Â· w* â‰¥ w_old Â· w* + Î³

So the "shadow" of w on wâˆ— grows by at least Î³ each mistake.

---

### Step 2: The length of w can't grow too fast

From the update:

||w_new||Â² = ||w_old||Â² + ||xáµ¢||Â² + 2yáµ¢(w_old Â· xáµ¢)

The last term is **negative or zero** when we make a mistake,

so:

||w_new||Â² â‰¤ ||w_old||Â² + RÂ²

After k mistakes:

||w_k|| â‰¤ Râˆšk

---

### Step 3: Combine both bounds

From Step 1 (projection grows linearly):

w_k Â· w* â‰¥ kÎ³

From Step 2 (norm grows like âˆšk):

w_k Â· w* â‰¤ ||w_k|| Â· ||w*|| â‰¤ Râˆšk

So:

kÎ³ â‰¤ Râˆšk

Divide both sides by âˆšk:

âˆšk â‰¤ R/Î³

Square both sides:

k â‰¤ (R/Î³)Â²

âœ… That's the formula.

---

### **The actual reason it converges**

The magic is in **both effects working together**:

- **Projection on wâˆ— keeps increasing** every mistake â€” you can't keep misclassifying forever without getting more aligned with the "right" direction.
- **Norm growth is bounded** â€” you can't have infinite increases in projection without the length catching up and violating the bound.

Eventually, these two constraints meet, forcing the algorithm to stop making mistakes.

## 5. **Limitations**

- **Only works** if the data is linearly separable (classic PLA).
- No notion of margin (unlike SVM).
- Sensitive to feature scaling â€” large-scale features dominate updates.
- May loop forever if data is not separable.

## 6. **Practical Tweaks**

- **Learning rate** Î·:
    
    Update rule becomes w â† w + Î·yáµ¢xáµ¢
    
    Doesnâ€™t affect convergence for separable data but can help stability.
    
- **Shuffling data** each pass can help avoid cycles.
- **Normalizing features** makes learning more stable.

## 7. **Connections to Other Methods**

- PLA is **stochastic gradient descent** on the **perceptron loss**:

L(w,b) = âˆ‘[iâˆˆmisclassified] âˆ’yáµ¢(wÂ·xáµ¢ + b)

- Related to **hinge loss** used in SVM, except SVM also enforces a margin.
- With non-linear features (via kernel trick) â†’ becomes the **Kernel Perceptron**.